{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/yekenot/pooled-gru-fasttext/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Dropout\n",
    "from keras.layers import GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/glove/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'glove' #'glove', 'fasttext\n",
    "\n",
    "if embeddings == 'fasttext':\n",
    "    EMBEDDING_FILE = '../data/fasttext/crawl-300d-2M.vec'\n",
    "else:\n",
    "    EMBEDDING_FILE = '../data/glove/glove.840B.300d.txt'    \n",
    "\n",
    "max_features = 30000 #100000\n",
    "maxlen = 200\n",
    "embed_size = 300\n",
    "\n",
    "print(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 300)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index), max_features\n",
    "embedding_matrix.shape\n",
    "#len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "mode = 'load' #'write'\n",
    "\n",
    "if max_features > 30000:\n",
    "    embedding_matrix_file = embeddings + '_embedding_matrix_feat_' + str(max_features) + '.pkl'\n",
    "    \n",
    "    if mode == 'write':\n",
    "        pickle.dump(x_train, open('../models/x_train_feat_' + str(max_features) + '_seq_200.pkl', 'wb'))\n",
    "        pickle.dump(x_test, open('../models/x_test_feat_' + str(max_features) + '_seq_200.pkl', 'wb'))\n",
    "        pickle.dump(embedding_matrix, open('../models/' + embedding_matrix_file, 'wb'))\n",
    "    else:        \n",
    "        x_train = pickle.load( open('../models/x_train_feat_' + str(max_features) + '_seq_200.pkl', 'rb') )\n",
    "        x_test = pickle.load( open('../models/x_test_feat_' + str(max_features) + '_seq_200.pkl', 'rb') )\n",
    "        embedding_matrix = pickle.load( open('../models/' + embedding_matrix_file, 'rb') )\n",
    "else:\n",
    "    embedding_matrix_file = embeddings + '_embedding_matrix.pkl'\n",
    "    \n",
    "    if mode == 'write':    \n",
    "        pickle.dump(x_train, open('../models/x_train_seq_200.pkl', 'wb'))\n",
    "        pickle.dump(x_test, open('../models/x_test_seq_200.pkl', 'wb'))\n",
    "        pickle.dump(embedding_matrix, open('../models/' + embedding_matrix_file, 'wb'))\n",
    "    else:\n",
    "        x_train = pickle.load( open('../models/x_train_seq_200.pkl', 'rb') )\n",
    "        x_test = pickle.load( open('../models/x_test_seq_200.pkl', 'rb') )\n",
    "        embedding_matrix = pickle.load( open('../models/' + embedding_matrix_file, 'rb') )\n",
    "    \n",
    "#train = pd.read_csv('../data/train.csv')\n",
    "#y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "#submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "#del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, recurrent_dropout=0.5))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GRU(128, return_sequences=True, recurrent_dropout=0.5)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # global pooling layer\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_2():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Bidirectional(GRU(256, return_sequences=True, recurrent_dropout=0.5))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    # 2-layer GPU\n",
    "    #x = GRU(256, return_sequences=True, recurrent_dropout=0.5)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    \n",
    "    #x = TimeDistributed(Dense(64, activation = \"relu\"))(x) # time distributed  (sigmoid)\n",
    "    \n",
    "    # global pooling layer\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_3(): #LSTM\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True, recurrent_dropout=0.5))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # 2-layer GPU\n",
    "    #x = GRU(256, return_sequences=True, recurrent_dropout=0.5)(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    \n",
    "    # global pooling layer\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model() \n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 32\n",
    "epochs = 2\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc], verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size=1024)\n",
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('../submissions/gru_l1_gru128_spatial_dr_0_4_gpu_dr_0_5_fasttext_maxpool_ep1_batch_128.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Records\n",
    "\n",
    "#### GRU (maxlen 100, Units 64) + FastText + MaxPool - Ep2 \n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "\n",
    "* Total params: 9,184,806\n",
    "\n",
    "* Epoch 1/2\n",
    " - 1442s - loss: 0.0499 - acc: 0.9820 - val_loss: 0.0464 - val_acc: 0.9821\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.987249 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 1436s - loss: 0.0379 - acc: 0.9852 - val_loss: 0.0449 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.987349 \n",
    "* ** LB 0.9812 **\n",
    " \n",
    " \n",
    " #### GRU (maxlen 100, , Units 64) + FastText + MaxPool - Ep3 \n",
    "\n",
    " Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/3\n",
    " - 1430s - loss: 0.0316 - acc: 0.9876 - val_loss: 0.0468 - val_acc: 0.9823\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.986716 \n",
    "\n",
    "* Epoch 2/3\n",
    " - 1397s - loss: 0.0204 - acc: 0.9922 - val_loss: 0.0584 - val_acc: 0.9810\n",
    "\n",
    "* ROC-AUC - epoch: 3 - score: 0.984497 \n",
    "\n",
    "* ** LB 0.6068 **\n",
    "\n",
    " #### GRU (maxlen 200, Units 64) + FastText + MaxPool - Ep3 \n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "* Total params: 9,184,806\n",
    "\n",
    "* Epoch 1/2\n",
    " - 2454s - loss: 0.0476 - acc: 0.9823 - val_loss: 0.0440 - val_acc: 0.9834\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988144 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 2556s - loss: 0.0370 - acc: 0.9854 - val_loss: 0.0445 - val_acc: 0.9828\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988467 \n",
    "\n",
    "* Epoch 2/2\n",
    "\n",
    "* ** LB 0.9813 **\n",
    "\n",
    " #### GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep2\n",
    "\n",
    "* Total params: 9,332,550\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 3034s - loss: 0.0487 - acc: 0.9821 - val_loss: 0.0435 - val_acc: 0.9832\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988728 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 3028s - loss: 0.0367 - acc: 0.9855 - val_loss: 0.0436 - val_acc: 0.9834\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988866 \n",
    " \n",
    " * **LB 0.9823**\n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2\n",
    " \n",
    "* Total params: 9,861,702\n",
    " \n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 5415s - loss: 0.0476 - acc: 0.9823 - val_loss: 0.0430 - val_acc: 0.9836\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988848 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 5429s - loss: 0.0370 - acc: 0.9855 - val_loss: 0.0444 - val_acc: 0.9827\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988651 \n",
    " \n",
    " \n",
    "#### GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4\n",
    "  \n",
    "*  Total params: 9,332,550\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "\n",
    "* Epoch 1/2\n",
    " - 3130s - loss: 0.0537 - acc: 0.9807 - val_loss: 0.0446 - val_acc: 0.9827\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.987232 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 3007s - loss: 0.0418 - acc: 0.9839 - val_loss: 0.0435 - val_acc: 0.9835\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988311 \n",
    " \n",
    " \n",
    "#### GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep1 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 128, Max features 30,000\n",
    "\n",
    "* Total params: 9,332,550\n",
    " \n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/1\n",
    " - 2375s - loss: 0.0373 - acc: 0.9853 - val_loss: 0.0438 - val_acc: 0.9832\n",
    "\n",
    "* ROC-AUC - epoch: 1 - score: 0.988689 \n",
    "\n",
    "* **LB 0.9832**\n",
    "\n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 128, Max features 30,000\n",
    " \n",
    "* Total params: 9,861,702\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 701s - loss: 0.0445 - acc: 0.9831 - val_loss: 0.0478 - val_acc: 0.9815\n",
    " - ROC-AUC - epoch: 1 - score: 0.987924 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 704s - loss: 0.0406 - acc: 0.9843 - val_loss: 0.0453 - val_acc: 0.9823\n",
    " - ROC-AUC - epoch: 2 - score: 0.989146\n",
    " \n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep5 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 128, Max features 30,000 - Optimizer: nadam?\n",
    "\n",
    "* Total params: 9,861,702\n",
    " \n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/5\n",
    " - 702s - loss: 0.0384 - acc: 0.9849 - val_loss: 0.0445 - val_acc: 0.9827\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.989080 \n",
    "\n",
    "* Epoch 2/5\n",
    " - 703s - loss: 0.0365 - acc: 0.9857 - val_loss: 0.0441 - val_acc: 0.9826\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989194 \n",
    "\n",
    "* Epoch 3/5\n",
    " - 702s - loss: 0.0348 - acc: 0.9862 - val_loss: 0.0451 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988923 \n",
    "\n",
    "* Epoch 4/5\n",
    " - 702s - loss: 0.0332 - acc: 0.9867 - val_loss: 0.0481 - val_acc: 0.9815\n",
    "\n",
    " ROC-AUC - epoch: 4 - score: 0.988581 \n",
    " \n",
    "* Epoch 5/5\n",
    " - 702s - loss: 0.0320 - acc: 0.9872 - val_loss: 0.0477 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 5 - score: 0.988151 \n",
    " \n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 256, Max features 30,000 - Optimizer: nadam\n",
    "\n",
    "* Total params: 9,478,854\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 447s - loss: 0.0588 - acc: 0.9794 - val_loss: 0.0510 - val_acc: 0.9801\n",
    "\n",
    " - ROC-AUC - epoch: 1 - score: 0.985962 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 445s - loss: 0.0434 - acc: 0.9835 - val_loss: 0.0496 - val_acc: 0.9805\n",
    "\n",
    " - ROC-AUC - epoch: 2 - score: 0.987739 \n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 256, Max features 30,000 - Optimizer: adam\n",
    "\n",
    "* Total params: 9,861,702\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 444s - loss: 0.0693 - acc: 0.9768 - val_loss: 0.0536 - val_acc: 0.9799\n",
    "\n",
    " - ROC-AUC - epoch: 1 - score: 0.976985 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 442s - loss: 0.0466 - acc: 0.9827 - val_loss: 0.0484 - val_acc: 0.9811\n",
    "\n",
    " - ROC-AUC - epoch: 2 - score: 0.986464 \n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 128, Max features 30,000 - Optimizer: adam\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 701s - loss: 0.0619 - acc: 0.9789 - val_loss: 0.0537 - val_acc: 0.9792\n",
    "\n",
    " - ROC-AUC - epoch: 1 - score: 0.982604 \n",
    "\n",
    "* Epoch 2/2\n",
    "  - 692s - loss: 0.0451 - acc: 0.9830 - val_loss: 0.0476 - val_acc: 0.9815\n",
    "  - ROC-AUC - epoch: 2 - score: 0.987292 \n",
    " \n",
    "  \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.5 - Batch size 128, Max features 30,000 - Optimizer: nadam\n",
    "\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 698s - loss: 0.0546 - acc: 0.9805 - val_loss: 0.0460 - val_acc: 0.9829\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.987629 \n",
    "\n",
    "Epoch 2/3\n",
    " - 696s - loss: 0.0424 - acc: 0.9837 - val_loss: 0.0439 - val_acc: 0.9827\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988500 \n",
    "\n",
    "Epoch 3/3\n",
    " - 694s - loss: 0.0395 - acc: 0.9846 - val_loss: 0.0486 - val_acc: 0.9813\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.987784 \n",
    "      \n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep5 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 30,000 - Optimizer: adam\n",
    "\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 442s - loss: 0.0388 - acc: 0.9850 - val_loss: 0.0471 - val_acc: 0.9811\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988906 \n",
    "\n",
    "Epoch 2/5\n",
    " - 443s - loss: 0.0366 - acc: 0.9855 - val_loss: 0.0440 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989002 \n",
    "\n",
    "Epoch 3/5\n",
    " - 443s - loss: 0.0349 - acc: 0.9861 - val_loss: 0.0441 - val_acc: 0.9830\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.989010 \n",
    "\n",
    "Epoch 4/5\n",
    " - 443s - loss: 0.0330 - acc: 0.9868 - val_loss: 0.0460 - val_acc: 0.9819\n",
    "\n",
    " ROC-AUC - epoch: 4 - score: 0.988410 \n",
    "\n",
    "Epoch 5/5\n",
    "\n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep3 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 30,000 - Optimizer: adam\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 444s - loss: 0.0676 - acc: 0.9773 - val_loss: 0.0487 - val_acc: 0.9815\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.982159 \n",
    "\n",
    "Epoch 2/3\n",
    " - 442s - loss: 0.0450 - acc: 0.9832 - val_loss: 0.0479 - val_acc: 0.9812\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.987763 \n",
    "\n",
    "Epoch 3/3\n",
    " - 442s - loss: 0.0412 - acc: 0.9841 - val_loss: 0.0447 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988995 \n",
    " \n",
    "* **LB 0.9821**\n",
    " \n",
    " \n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep3 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 128, Max features 30,000 - Optimizer: adam\n",
    "\n",
    " \n",
    " Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 687s - loss: 0.0396 - acc: 0.9847 - val_loss: 0.0465 - val_acc: 0.9815\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988641 \n",
    "\n",
    "Epoch 2/3\n",
    " - 687s - loss: 0.0371 - acc: 0.9854 - val_loss: 0.0442 - val_acc: 0.9829\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988676 \n",
    "\n",
    "Epoch 3/3\n",
    " - 687s - loss: 0.0350 - acc: 0.9861 - val_loss: 0.0446 - val_acc: 0.9824\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988746\n",
    " \n",
    " ----\n",
    " \n",
    " #### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 100,000 - Optimizer: adam\n",
    "\n",
    "* Total params: 30,861,702\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 457s - loss: 0.0679 - acc: 0.9769 - val_loss: 0.0484 - val_acc: 0.9814\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.982566 \n",
    "\n",
    "Epoch 2/2\n",
    " - 456s - loss: 0.0451 - acc: 0.9830 - val_loss: 0.0491 - val_acc: 0.9803\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.986838 \n",
    "\n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep5 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 100,000 - Optimizer: adam\n",
    "\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 456s - loss: 0.0407 - acc: 0.9843 - val_loss: 0.0442 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.989354 \n",
    "\n",
    "Epoch 2/5\n",
    " - 456s - loss: 0.0375 - acc: 0.9852 - val_loss: 0.0439 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989724 \n",
    "\n",
    "Epoch 3/5\n",
    "\n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep3 -  dropout (external) =0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 100,000 - Optimizer: adam\n",
    "\n",
    "**Attempt 1**\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 473s - loss: 0.0530 - acc: 0.9806 - val_loss: 0.0598 - val_acc: 0.9826\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.989032 \n",
    "\n",
    "Epoch 2/3\n",
    " - 461s - loss: 0.0390 - acc: 0.9847 - val_loss: 0.0513 - val_acc: 0.9827\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989377 \n",
    " \n",
    "**Attempt 2**\n",
    " \n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 462s - loss: 0.0507 - acc: 0.9814 - val_loss: 0.0720 - val_acc: 0.9767\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988744 \n",
    "\n",
    "Epoch 2/3\n",
    " - 462s - loss: 0.0385 - acc: 0.9848 - val_loss: 0.0509 - val_acc: 0.9819\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989492 \n",
    "\n",
    "Epoch 3/3\n",
    " - 462s - loss: 0.0335 - acc: 0.9865 - val_loss: 0.0599 - val_acc: 0.9772\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988826 \n",
    " \n",
    "**Attempt 2** (With nadam, external Dropout and ep 2)\n",
    " \n",
    " Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 464s - loss: 0.0534 - acc: 0.9804 - val_loss: 0.0620 - val_acc: 0.9736\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988188 \n",
    "\n",
    "Epoch 2/2\n",
    " - 461s - loss: 0.0393 - acc: 0.9846 - val_loss: 0.0528 - val_acc: 0.9788\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989730\n",
    " \n",
    " * **LB 0.9827**\n",
    "\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "#### LSTM (maxlen 200, Units 256) + FastText + MaxPool - Ep5 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4  - Batch size 128, Max features 100,000 - Optimizer: nadam\n",
    "\n",
    "* Total params: 9,442,374\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 910s - loss: 0.0502 - acc: 0.9816 - val_loss: 0.0590 - val_acc: 0.9825\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.989202 \n",
    "\n",
    "Epoch 2/5\n",
    " - 906s - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0505 - val_acc: 0.9823\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989451 \n",
    "\n",
    "Epoch 3/5\n",
    " - 906s - loss: 0.0323 - acc: 0.9871 - val_loss: 0.0492 - val_acc: 0.9823\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988694 \n",
    "\n",
    "Epoch 4/5\n",
    " - 906s - loss: 0.0266 - acc: 0.9895 - val_loss: 0.0501 - val_acc: 0.9801\n",
    "\n",
    " ROC-AUC - epoch: 4 - score: 0.986024 \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stacked GRU\n",
    "\n",
    "#### L2 - GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep2 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 128, Max features 30,000\n",
    " \n",
    "* Total params: 9,478,854\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 3217s - loss: 0.0448 - acc: 0.9830 - val_loss: 0.0531 - val_acc: 0.9832\n",
    "\n",
    " - ROC-AUC - epoch: 1 - score: 0.987085 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 3194s - loss: 0.0393 - acc: 0.9846 - val_loss: 0.0582 - val_acc: 0.9809\n",
    "\n",
    " - ROC-AUC - epoch: 2 - score: 0.987217 \n",
    " \n",
    " \n",
    "#### L2 - GRU (maxlen 200, Units 256) + FastText + MaxPool - Ep5 -  dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 256, Max features 100,000\n",
    "\n",
    "* Total params: 31,449,222\n",
    " \n",
    " ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpatialDropout rate\n",
    "\n",
    "##### 0.3 - GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep3 (trained on GPU - K80)\n",
    " \n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 2073s - loss: 0.0494 - acc: 0.9819 - val_loss: 0.0435 - val_acc: 0.9832\n",
    "\n",
    "* ROC-AUC - epoch: 1 - score: 0.988933 \n",
    "\n",
    "Epoch 2/2\n",
    "\n",
    "##### 0.3 - GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep3 (trained on CPU quad core)\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 2891s - loss: 0.0489 - acc: 0.9820 - val_loss: 0.0437 - val_acc: 0.9830\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988025 \n",
    "\n",
    "Epoch 2/2\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988614 \n",
    "\n",
    "* **LB 0.9822**\n",
    "\n",
    "##### 0.4 - GRU (maxlen 200, Units 128) + FastText + MaxPool - Ep3 (trained on GPU - V100)\n",
    "\n",
    "* Train on 151592 samples, validate on 7979 samples\n",
    "* Epoch 1/2\n",
    " - 2189s - loss: 0.0499 - acc: 0.9816 - val_loss: 0.0438 - val_acc: 0.9832\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988505 \n",
    "\n",
    "* Epoch 2/2\n",
    " - 2149s - loss: 0.0384 - acc: 0.9850 - val_loss: 0.0435 - val_acc: 0.9837\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988554 \n",
    " \n",
    " * **0.9825**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Multiple Dense layers\n",
    "\n",
    "#### GRU (maxlen 200, Units 256) + FastText -> Spatial Dropout 0.4, dropout (external) =0.5, recurrent_dropout=0.5 -> MaxPool -> Dense (64, relu) - Ep5 - Batch size 256, Max features 100,000 - Optimizer: adam\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 459s - loss: 0.0643 - acc: 0.9775 - val_loss: 0.0518 - val_acc: 0.9791\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.983117 \n",
    "\n",
    "Epoch 2/5\n",
    " - 458s - loss: 0.0463 - acc: 0.9824 - val_loss: 0.0478 - val_acc: 0.9828\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.986829 \n",
    "\n",
    "Epoch 3/5\n",
    " - 458s - loss: 0.0418 - acc: 0.9834 - val_loss: 0.0501 - val_acc: 0.9804\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.986362 \n",
    "\n",
    "Epoch 4/5\n",
    " - 458s - loss: 0.0379 - acc: 0.9847 - val_loss: 0.0478 - val_acc: 0.9829\n",
    "\n",
    " ROC-AUC - epoch: 4 - score: 0.985988 \n",
    "\n",
    "Epoch 5/5\n",
    " - 458s - loss: 0.0349 - acc: 0.9855 - val_loss: 0.0482 - val_acc: 0.9823\n",
    "\n",
    " ROC-AUC - epoch: 5 - score: 0.986694 \n",
    " \n",
    "**Attempt 2 (Batch 128) **\n",
    " \n",
    " Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 706s - loss: 0.0357 - acc: 0.9854 - val_loss: 0.0511 - val_acc: 0.9808\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.985459 \n",
    "\n",
    "Epoch 2/5\n",
    " - 706s - loss: 0.0332 - acc: 0.9864 - val_loss: 0.0547 - val_acc: 0.9804\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.984432 \n",
    "\n",
    "Epoch 3/5\n",
    " - 706s - loss: 0.0312 - acc: 0.9870 - val_loss: 0.0572 - val_acc: 0.9812\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.984002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
