{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://www.kaggle.com/umbertogriffo/combined-gru-and-cnn-fasttext-badwords/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import h5py\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Dropout\n",
    "from keras.layers import GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback, CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/glove/glove.840B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'glove' #'glove', 'fasttext\n",
    "\n",
    "if embeddings == 'fasttext':\n",
    "    EMBEDDING_FILE = '../data/fasttext/crawl-300d-2M.vec'\n",
    "else:\n",
    "    EMBEDDING_FILE = '../data/glove/glove.840B.300d.txt'    \n",
    "\n",
    "max_features = 100000  #100000 , 30000\n",
    "maxlen = 200\n",
    "embed_size = 300\n",
    "prefix = 'c1' #x, #c1\n",
    "\n",
    "print(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "X_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\"fillna\").values\n",
    "\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(word_index), max_features\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_feats_path = '../models/{}_train_feat_{}_seq_{}.pkl'.format(prefix, max_features, maxlen)\n",
    "test_feats_path = '../models/{}_test_feat_{}_seq_{}.pkl'.format(prefix, max_features, maxlen)\n",
    "embedding_matrix_path = '../models/{}_{}_embedding_matrix_feat_{}.pkl'.format(prefix, embeddings, max_features)\n",
    "\n",
    "#pickle.dump(x_train, open(train_feats_path, 'wb'))\n",
    "#pickle.dump(x_test, open(test_feats_path, 'wb'))\n",
    "#pickle.dump(embedding_matrix, open(embedding_matrix_path, 'wb'))\n",
    "\n",
    "x_train = pickle.load(open(train_feats_path, 'rb') )\n",
    "x_test = pickle.load(open(test_feats_path, 'rb') )\n",
    "embedding_matrix = pickle.load(open(embedding_matrix_path, 'rb') )\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "            # stopping condition - ROC stops improving\n",
    "            if score > self.best:\n",
    "                self.best = score\n",
    "            else:\n",
    "                pass\n",
    "                #self.stopped_epoch = epoch\n",
    "                #self.model.stop_training = True\n",
    "                #print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
    "                \n",
    "\n",
    "def build_model():\n",
    "    input = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(input)\n",
    "    x = SpatialDropout1D(0.4)(x)\n",
    "    x = Bidirectional(LSTM(80, return_sequences=True, recurrent_dropout=0.2, dropout=0.2))(x)\n",
    "\n",
    "    # http://konukoii.com/blog/2018/02/19/twitter-sentiment-analysis-using-combined-lstm-cnn-models/\n",
    "    # For text, CNN -> LSTM (or GRU) doesn't seem to work well, but LSTM -> CNN works really well.\n",
    "    x1 = Conv1D(filters=64, kernel_size=2, padding='valid', kernel_initializer=\"he_uniform\")(x)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    \n",
    "    x2 = Conv1D(filters=64, kernel_size=3, padding='valid', kernel_initializer=\"he_uniform\")(x)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    \n",
    "    # Global average pooling operation for temporal data.\n",
    "    # https://www.quora.com/What-is-global-average-pooling\n",
    "    avg_pool0 = GlobalAveragePooling1D()(x)\n",
    "    # Global max pooling operation for temporal data.\n",
    "    max_pool0 = GlobalMaxPooling1D()(x)    \n",
    "\n",
    "    # Global average pooling operation for temporal data.\n",
    "    # https://www.quora.com/What-is-global-average-pooling\n",
    "    avg_pool1 = GlobalAveragePooling1D()(x1)\n",
    "    # Global max pooling operation for temporal data.\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    # Global average pooling operation for temporal data.\n",
    "    # https://www.quora.com/What-is-global-average-pooling\n",
    "    avg_pool2 = GlobalAveragePooling1D()(x2)\n",
    "    # Global max pooling operation for temporal data.\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    \n",
    "    conc = concatenate([avg_pool0, max_pool0, avg_pool1, max_pool1, avg_pool2, max_pool2])\n",
    "\n",
    "    #output = Dense(64, activation=\"relu\")(conc)\n",
    "    #output = Dropout(0.2)(output)\n",
    "    \n",
    "    output = Dense(6, activation=\"sigmoid\")(conc)\n",
    "        \n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    \n",
    "    return model \n",
    "\n",
    "def build_model_2(units = 0, dr = 0.0):\n",
    "    inp = Input(shape = (maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x = SpatialDropout1D(dr)(x)\n",
    "\n",
    "    x = Bidirectional(GRU(units, return_sequences = True))(x)\n",
    "    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "\n",
    "    x = Dense(6, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 200, 300)     30000000    input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 200, 300)     0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 200, 256)     329472      spatial_dropout1d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 199, 64)      32832       bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 64)           0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 128)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            774         concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 30,363,078\n",
      "Trainable params: 363,078\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = get_model()\n",
    "model = build_model_2(units = 128, dr = 0.2)\n",
    "opt = Nadam(lr=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 32\n",
    "epochs = 3\n",
    "\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "CheckPoint = ModelCheckpoint('../snapshots/cnn_weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "csv_logger = CSVLogger('../training.log')\n",
    "\n",
    "hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n",
    "                 callbacks=[RocAuc, csv_logger, CheckPoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified k-fold learning & inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 1 / 10\n",
      "Training / Valid set counts (151582,) / (7989,)\n",
      "Train on 151582 samples, validate on 7989 samples\n",
      "Epoch 1/5\n",
      " - 499s - loss: 0.0548 - acc: 0.9801 - val_loss: 0.0458 - val_acc: 0.9823\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988215 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04577, saving model to ../snapshots/cnn_glove_128_fold_0.hdf5\n",
      "Epoch 2/5\n",
      " - 496s - loss: 0.0420 - acc: 0.9838 - val_loss: 0.0434 - val_acc: 0.9830\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989699 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04577 to 0.04336, saving model to ../snapshots/cnn_glove_128_fold_0.hdf5\n",
      "Epoch 3/5\n",
      " - 494s - loss: 0.0392 - acc: 0.9846 - val_loss: 0.0410 - val_acc: 0.9834\n",
      " - 494s - loss: 0.0369 - acc: 0.9855 - val_loss: 0.0414 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.990447 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 495s - loss: 0.0346 - acc: 0.9863 - val_loss: 0.0420 - val_acc: 0.9837\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.990656 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 2 / 10\n",
      "Training / Valid set counts (151588,) / (7983,)\n",
      "Train on 151588 samples, validate on 7983 samples\n",
      "Epoch 1/5\n",
      " - 495s - loss: 0.0490 - acc: 0.9815 - val_loss: 0.0429 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.986565 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04287, saving model to ../snapshots/cnn_glove_128_fold_1.hdf5\n",
      "Epoch 2/5\n",
      " - 490s - loss: 0.0397 - acc: 0.9844 - val_loss: 0.0422 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988550 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04287 to 0.04218, saving model to ../snapshots/cnn_glove_128_fold_1.hdf5\n",
      "Epoch 3/5\n",
      " - 488s - loss: 0.0369 - acc: 0.9853 - val_loss: 0.0402 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.988420 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04218 to 0.04022, saving model to ../snapshots/cnn_glove_128_fold_1.hdf5\n",
      "Epoch 4/5\n",
      " - 487s - loss: 0.0345 - acc: 0.9862 - val_loss: 0.0408 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987583 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 489s - loss: 0.0317 - acc: 0.9874 - val_loss: 0.0411 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.988081 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 3 / 10\n",
      "Training / Valid set counts (151584,) / (7987,)\n",
      "Train on 151584 samples, validate on 7987 samples\n",
      "Epoch 1/5\n",
      " - 495s - loss: 0.0498 - acc: 0.9812 - val_loss: 0.0430 - val_acc: 0.9838\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.989095 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04302, saving model to ../snapshots/cnn_glove_128_fold_2.hdf5\n",
      "Epoch 2/5\n",
      " - 491s - loss: 0.0399 - acc: 0.9843 - val_loss: 0.0407 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.990101 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04302 to 0.04067, saving model to ../snapshots/cnn_glove_128_fold_2.hdf5\n",
      "Epoch 3/5\n",
      " - 488s - loss: 0.0370 - acc: 0.9854 - val_loss: 0.0410 - val_acc: 0.9845\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.990238 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 487s - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0417 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.990178 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 489s - loss: 0.0316 - acc: 0.9875 - val_loss: 0.0433 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.990246 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 4 / 10\n",
      "Training / Valid set counts (151588,) / (7983,)\n",
      "Train on 151588 samples, validate on 7983 samples\n",
      "Epoch 1/5\n",
      " - 490s - loss: 0.0495 - acc: 0.9813 - val_loss: 0.0418 - val_acc: 0.9827\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988935 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04178, saving model to ../snapshots/cnn_glove_128_fold_3.hdf5\n",
      "Epoch 2/5\n",
      " - 486s - loss: 0.0399 - acc: 0.9844 - val_loss: 0.0419 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989572 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "Epoch 3/5\n",
      " - 487s - loss: 0.0375 - acc: 0.9851 - val_loss: 0.0409 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.990008 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04178 to 0.04087, saving model to ../snapshots/cnn_glove_128_fold_3.hdf5\n",
      "Epoch 4/5\n",
      " - 486s - loss: 0.0348 - acc: 0.9861 - val_loss: 0.0417 - val_acc: 0.9829\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.990095 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 488s - loss: 0.0323 - acc: 0.9872 - val_loss: 0.0428 - val_acc: 0.9823\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.989314 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 5 / 10\n",
      "Training / Valid set counts (151591,) / (7980,)\n",
      "Train on 151591 samples, validate on 7980 samples\n",
      "Epoch 1/5\n",
      " - 493s - loss: 0.0488 - acc: 0.9817 - val_loss: 0.0400 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988108 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04003, saving model to ../snapshots/cnn_glove_128_fold_4.hdf5\n",
      "Epoch 2/5\n",
      " - 489s - loss: 0.0399 - acc: 0.9843 - val_loss: 0.0387 - val_acc: 0.9850\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988862 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04003 to 0.03867, saving model to ../snapshots/cnn_glove_128_fold_4.hdf5\n",
      "Epoch 3/5\n",
      " - 488s - loss: 0.0368 - acc: 0.9854 - val_loss: 0.0390 - val_acc: 0.9847\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.988510 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 487s - loss: 0.0341 - acc: 0.9865 - val_loss: 0.0394 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987687 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 486s - loss: 0.0317 - acc: 0.9874 - val_loss: 0.0402 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987638 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 6 / 10\n",
      "Training / Valid set counts (151576,) / (7995,)\n",
      "Train on 151576 samples, validate on 7995 samples\n",
      "Epoch 1/5\n",
      " - 491s - loss: 0.0485 - acc: 0.9817 - val_loss: 0.0428 - val_acc: 0.9831\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.987777 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04276, saving model to ../snapshots/cnn_glove_128_fold_5.hdf5\n",
      "Epoch 2/5\n",
      " - 490s - loss: 0.0398 - acc: 0.9844 - val_loss: 0.0413 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988355 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04276 to 0.04128, saving model to ../snapshots/cnn_glove_128_fold_5.hdf5\n",
      "Epoch 3/5\n",
      " - 489s - loss: 0.0368 - acc: 0.9854 - val_loss: 0.0428 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.987850 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 492s - loss: 0.0344 - acc: 0.9864 - val_loss: 0.0430 - val_acc: 0.9838\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987648 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 487s - loss: 0.0318 - acc: 0.9873 - val_loss: 0.0419 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.988112 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "153164/153164 [==============================] - 45s 293us/step\n",
      "Running fold 7 / 10\n",
      "Training / Valid set counts (151592,) / (7979,)\n",
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/5\n",
      " - 490s - loss: 0.0490 - acc: 0.9819 - val_loss: 0.0426 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.981500 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04261, saving model to ../snapshots/cnn_glove_128_fold_6.hdf5\n",
      "Epoch 2/5\n",
      " - 487s - loss: 0.0398 - acc: 0.9845 - val_loss: 0.0406 - val_acc: 0.9849\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.982064 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04261 to 0.04061, saving model to ../snapshots/cnn_glove_128_fold_6.hdf5\n",
      "Epoch 3/5\n",
      " - 489s - loss: 0.0368 - acc: 0.9854 - val_loss: 0.0409 - val_acc: 0.9847\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.984426 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 487s - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0404 - val_acc: 0.9850\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.984681 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04061 to 0.04042, saving model to ../snapshots/cnn_glove_128_fold_6.hdf5\n",
      "Epoch 5/5\n",
      " - 491s - loss: 0.0315 - acc: 0.9875 - val_loss: 0.0431 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.982457 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 8 / 10\n",
      "Training / Valid set counts (151582,) / (7989,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151582 samples, validate on 7989 samples\n",
      "Epoch 1/5\n",
      " - 496s - loss: 0.0493 - acc: 0.9816 - val_loss: 0.0420 - val_acc: 0.9837\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.987080 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04200, saving model to ../snapshots/cnn_glove_128_fold_7.hdf5\n",
      "Epoch 2/5\n",
      " - 493s - loss: 0.0400 - acc: 0.9844 - val_loss: 0.0417 - val_acc: 0.9838\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.987496 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04200 to 0.04168, saving model to ../snapshots/cnn_glove_128_fold_7.hdf5\n",
      "Epoch 3/5\n",
      " - 492s - loss: 0.0370 - acc: 0.9854 - val_loss: 0.0412 - val_acc: 0.9832\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.987612 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04168 to 0.04119, saving model to ../snapshots/cnn_glove_128_fold_7.hdf5\n",
      "Epoch 4/5\n",
      " - 488s - loss: 0.0346 - acc: 0.9863 - val_loss: 0.0419 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987654 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 487s - loss: 0.0326 - acc: 0.9871 - val_loss: 0.0424 - val_acc: 0.9832\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.986428 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "153164/153164 [==============================] - 45s 293us/step\n",
      "Running fold 9 / 10\n",
      "Training / Valid set counts (151594,) / (7977,)\n",
      "Train on 151594 samples, validate on 7977 samples\n",
      "Epoch 1/5\n",
      " - 491s - loss: 0.0402 - acc: 0.9842 - val_loss: 0.0393 - val_acc: 0.9847\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.987987 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04101 to 0.03929, saving model to ../snapshots/cnn_glove_128_fold_8.hdf5\n",
      "Epoch 3/5\n",
      " - 492s - loss: 0.0369 - acc: 0.9854 - val_loss: 0.0405 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986894 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 491s - loss: 0.0345 - acc: 0.9863 - val_loss: 0.0415 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.985220 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 492s - loss: 0.0316 - acc: 0.9873 - val_loss: 0.0412 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987110 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "153164/153164 [==============================] - 45s 294us/step\n",
      "Running fold 10 / 10\n",
      "Training / Valid set counts (151596,) / (7975,)\n",
      "Train on 151596 samples, validate on 7975 samples\n",
      "Epoch 1/5\n",
      " - 495s - loss: 0.0490 - acc: 0.9817 - val_loss: 0.0392 - val_acc: 0.9838\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.990503 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03923, saving model to ../snapshots/cnn_glove_128_fold_9.hdf5\n",
      "Epoch 2/5\n",
      " - 491s - loss: 0.0400 - acc: 0.9843 - val_loss: 0.0385 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.991268 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03923 to 0.03848, saving model to ../snapshots/cnn_glove_128_fold_9.hdf5\n",
      "Epoch 3/5\n",
      " - 492s - loss: 0.0372 - acc: 0.9853 - val_loss: 0.0400 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.990479 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/5\n",
      " - 488s - loss: 0.0346 - acc: 0.9862 - val_loss: 0.0405 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.990313 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/5\n",
      " - 486s - loss: 0.0320 - acc: 0.9874 - val_loss: 0.0415 - val_acc: 0.9834\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.989965 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 00005: early stopping\n",
      "153164/153164 [==============================] - 45s 293us/step\n"
     ]
    }
   ],
   "source": [
    "## Stratified k-fold training\n",
    "\n",
    "n_folds = 10\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "predict_batch_size = 1024\n",
    "run_id = 'cnn_glove_128'\n",
    "opt = Adam(lr = 0.001, decay = 0) #Nadam(lr=0.002) #optimizer\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 20, shuffle = True, random_state = 32)\n",
    "\n",
    "csv_logger = CSVLogger('../training.log')\n",
    "early_stop = EarlyStopping(verbose=2, monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "\n",
    "pred = np.zeros((x_test.shape[0], 6))\n",
    "y_packed = np.packbits(y_train, axis=1)\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(kfold.split(x_train, y_packed)):\n",
    "    print(\"Running fold {} / {}\".format(i + 1, n_folds))\n",
    "    print(\"Training / Valid set counts {} / {}\".format(train_idx.shape, valid_idx.shape))\n",
    "\n",
    "    model = None    \n",
    "    model = build_model_2(units = 128, dr = 0.2)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    \n",
    "    xs_train, ys_train = x_train[train_idx], y_train[train_idx] \n",
    "    xs_valid, ys_valid = x_train[valid_idx], y_train[valid_idx]\n",
    "\n",
    "    #check_point = ModelCheckpoint('../snapshots/' + run_id + '_fold_' + str(i) + '_weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "    roc_auc = RocAucEvaluation(validation_data=(xs_valid, ys_valid), interval=1)\n",
    "    check_point = ModelCheckpoint('../snapshots/' + run_id + '_fold_' + str(i) +'.hdf5', monitor = \"val_loss\", \n",
    "                                  verbose = 1, save_best_only = True, mode = \"min\")\n",
    "\n",
    "    # training\n",
    "    history = model.fit(xs_train, ys_train, batch_size = batch_size, epochs = epochs, validation_data = (xs_valid, ys_valid), \n",
    "                          verbose = 2, callbacks=[roc_auc, csv_logger, check_point, early_stop])        \n",
    "    # predict\n",
    "    pred += model.predict(x_test, batch_size = predict_batch_size, verbose = 1)\n",
    "\n",
    "    if (i + 1) == n_folds: break    \n",
    "    \n",
    "y_pred = pred/n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = load_model('../snapshots/lstm_glove_fold_0_weights.02-0.04.hdf5')\n",
    "mod2 = load_model('../snapshots/lstm_glove_fold_1_weights.02-0.04.hdf5')\n",
    "\n",
    "pred1 = mod1.predict(x_test, batch_size = predict_batch_size, verbose = 1)\n",
    "pred2 = mod2.predict(x_test, batch_size = predict_batch_size, verbose = 1)\n",
    "\n",
    "y_pred1 = (pred1 + pred2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lstm_glove_fold_0_weights.03-0.04.hdf5'\n",
    "model = load_model('../snapshots/' + model_name)\n",
    "y_pred = model.predict(x_test, batch_size=1024)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\n",
    "submission.to_csv('../submissions/cnn_2_window_2_3_filter_64_l1_lstm80_spatial_dr_0_4_lstm_dr_0_2_dense_64_dr_0_2_glove_ep3_batch_128.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN (filters 64, window 2 (dropout 0.2) and window 3 (dropout 0.2) ) + LSTM (80, dropout=0.2, recurrent_dropout=0.2 - Spatial Dropout 0.4) + Glove + last dense 64 dropout (0.2) - Ep3 - Batch size 128, Max features 100,000\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 902s - loss: 0.0565 - acc: 0.9801 - val_loss: 0.0450 - val_acc: 0.9818\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.986522 \n",
    "\n",
    "Epoch 2/3\n",
    " - 880s - loss: 0.0417 - acc: 0.9837 - val_loss: 0.0421 - val_acc: 0.9832\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989570 \n",
    "\n",
    "Epoch 3/3\n",
    " - 872s - loss: 0.0372 - acc: 0.9849 - val_loss: 0.0414 - val_acc: 0.9841\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.990200 \n",
    " \n",
    " * **LB 0.9830**\n",
    "\n",
    "\n",
    "#### CNN (filters 64, window 2 (dropout 0.2) and window 3 (dropout 0.2) ) + LSTM (80, dropout=0.2, recurrent_dropout=0.2 - Spatial Dropout 0.4) + Glove + last dense 64 dropout (0.1) - Ep3 - Batch size 128, Max features 100,000\n",
    "\n",
    "\n",
    "* Name: **cnn_2_window_2_3_filter_64_l1_lstm80_spatial_dr_0_4_lstm_dr_0_2_fasttext_ep3_batch_128.csv**\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 881s - loss: 0.0577 - acc: 0.9798 - val_loss: 0.0449 - val_acc: 0.9822\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.984894 \n",
    "\n",
    "Epoch 2/3\n",
    " - 875s - loss: 0.0413 - acc: 0.9839 - val_loss: 0.0415 - val_acc: 0.9837\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989601 \n",
    "\n",
    "Epoch 3/3\n",
    " - 870s - loss: 0.0365 - acc: 0.9854 - val_loss: 0.0406 - val_acc: 0.9839\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.990294 \n",
    "\n",
    "* **LB 0.9833**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### CNN (filters 64, window 2 (dropout 0.2) and window 3 (dropout 0.2) ) + LSTM (64, dropout=0.2, recurrent_dropout=0.2 - Spatial Dropout 0.4) + FastText + MaxPool - Ep2 - Batch size 128, Max features 100,000\n",
    "\n",
    "* Total params: 30,332,486\n",
    "\n",
    "**Attempt 1**\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 876s - loss: 0.0325 - acc: 0.9866 - val_loss: 0.0430 - val_acc: 0.9837\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.989429 \n",
    "\n",
    "Epoch 2/2\n",
    " - 877s - loss: 0.0292 - acc: 0.9879 - val_loss: 0.0446 - val_acc: 0.9836\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989135 \n",
    " \n",
    " \n",
    " **Attempt 2**\n",
    " \n",
    " * name: **cnn_2_window_2_3_l1_lstm256_spatial_dr_0_4_lstm_dr_0_2_fasttext_maxpool_ep2_batch_128.csv**\n",
    " \n",
    " Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 887s - loss: 0.0552 - acc: 0.9803 - val_loss: 0.0445 - val_acc: 0.9821\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.987122 \n",
    "\n",
    "Epoch 2/2\n",
    " - 868s - loss: 0.0409 - acc: 0.9840 - val_loss: 0.0413 - val_acc: 0.9837\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989921 \n",
    "\n",
    "\n",
    "#### CNN (filters 64, window 2 and window 3) + LSTM (256, dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4) + FastText + MaxPool - Ep3 - Batch size 256, Max features 100,000\n",
    "\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 655s - loss: 0.0576 - acc: 0.9794 - val_loss: 0.0547 - val_acc: 0.9788\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988215 \n",
    "\n",
    "Epoch 2/3\n",
    " - 623s - loss: 0.0427 - acc: 0.9837 - val_loss: 0.0498 - val_acc: 0.9813\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.988926 \n",
    "\n",
    "Epoch 3/3\n",
    " - 624s - loss: 0.0379 - acc: 0.9851 - val_loss: 0.0546 - val_acc: 0.9815\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988650 \n",
    "\n",
    "**Attempt 2**\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 627s - loss: 0.0346 - acc: 0.9863 - val_loss: 0.0566 - val_acc: 0.9806\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988491 \n",
    "\n",
    "Epoch 2/3\n",
    " - 628s - loss: 0.0311 - acc: 0.9877 - val_loss: 0.0479 - val_acc: 0.9818\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.987230 \n",
    "\n",
    "Epoch 3/3\n",
    " - 629s - loss: 0.0283 - acc: 0.9888 - val_loss: 0.0552 - val_acc: 0.9801\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.986574 \n",
    "\n",
    "**Attempt 3**\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/3\n",
    " - 639s - loss: 0.0572 - acc: 0.9794 - val_loss: 0.0913 - val_acc: 0.9669\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.983046 \n",
    "\n",
    "Epoch 2/3\n",
    " - 635s - loss: 0.0409 - acc: 0.9841 - val_loss: 0.0500 - val_acc: 0.9802\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989757 \n",
    "\n",
    "Epoch 3/3\n",
    " - 637s - loss: 0.0361 - acc: 0.9857 - val_loss: 0.0575 - val_acc: 0.9774\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.988192 \n",
    "\n",
    "\n",
    "**Attempt 4**\n",
    "\n",
    "* Total params: 31,312,390\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/2\n",
    " - 643s - loss: 0.0571 - acc: 0.9797 - val_loss: 0.0528 - val_acc: 0.9790\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.988197 \n",
    "\n",
    "Epoch 2/2\n",
    " - 640s - loss: 0.0411 - acc: 0.9841 - val_loss: 0.0443 - val_acc: 0.9831\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.989429 \n",
    "\n",
    "**LB 0.9837**\n",
    "\n",
    "\n",
    "#### CNN (filters 128, window 2) + GRU (256) + FastText + MaxPool - Ep3 - dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 128, Max features 100,000\n",
    "\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 724s - loss: 0.0551 - acc: 0.9803 - val_loss: 0.0943 - val_acc: 0.9755\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.981225 \n",
    "\n",
    "Epoch 2/5\n",
    " - 722s - loss: 0.0431 - acc: 0.9835 - val_loss: 0.0731 - val_acc: 0.9794\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.983226 \n",
    "\n",
    "Epoch 3/5\n",
    " - 722s - loss: 0.0381 - acc: 0.9851 - val_loss: 0.0652 - val_acc: 0.9781\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.985856 \n",
    "\n",
    "Epoch 4/5\n",
    " - 722s - loss: 0.0438 - acc: 0.9848 - val_loss: 0.0803 - val_acc: 0.9714\n",
    "\n",
    " ROC-AUC - epoch: 4 - score: 0.973663 \n",
    "\n",
    "Epoch 5/5\n",
    "\n",
    "#### CNN (filters 64, window 2) + GRU (256) + FastText + MaxPool - Ep3 - dropout=0.5, recurrent_dropout=0.5 - Spatial Dropout 0.4 - Batch size 128, Max features 100,000\n",
    "\n",
    "Train on 151592 samples, validate on 7979 samples\n",
    "Epoch 1/5\n",
    " - 717s - loss: 0.0550 - acc: 0.9802 - val_loss: 0.0644 - val_acc: 0.9816\n",
    "\n",
    " ROC-AUC - epoch: 1 - score: 0.987303 \n",
    "\n",
    "Epoch 2/5\n",
    " - 714s - loss: 0.0422 - acc: 0.9837 - val_loss: 0.0643 - val_acc: 0.9816\n",
    "\n",
    " ROC-AUC - epoch: 2 - score: 0.973863 \n",
    "\n",
    "Epoch 3/5\n",
    " - 714s - loss: 0.0465 - acc: 0.9829 - val_loss: 0.1030 - val_acc: 0.9644\n",
    "\n",
    " ROC-AUC - epoch: 3 - score: 0.978108 \n",
    "\n",
    "Epoch 4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
